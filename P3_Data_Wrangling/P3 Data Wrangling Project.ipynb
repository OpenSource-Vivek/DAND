{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "OpenStreetMap Data Case Study\n",
    "11/16/2016\n",
    "Scott Tse\n",
    "\n",
    "I chose to investigate the OSM data for the city of Portland, OR where I feel very fortunate to live.\n",
    "https://www.openstreetmap.org/search?query=portland%2C%20or#map=12/45.5234/-122.6762\n",
    "\n",
    "I extracted the compressed OSM data in XML format (84MB) from MAPZEN, following this link: \n",
    "https://mapzen.com/data/metro-extracts/metro/portland_oregon/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.cElementTree as ET  # Used cElementTree to speed things up\n",
    "                                    \n",
    "OSM_FILE = \"portland_oregon.osm\"  # unzipped OSM file from MAPZEN\n",
    "SAMPLE_FILE = \"sample.osm\" # name of reduced sample file\n",
    "\n",
    "k = 500 # Parameter: take every k-th top level element\n",
    "      # initially used k = 100 to reduce size of dataset and parsing time\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use this function to take a look at the first n rows of the SAMPLE FILE, verify that code above ran properly\n",
    "\n",
    "def file_look(file, rows):\n",
    "    with open(file, \"r\") as f:\n",
    "        for i, row in enumerate(f):\n",
    "            print row\n",
    "            if i >= rows:\n",
    "                break\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "\n",
      "<osm>\n",
      "\n",
      "  <node changeset=\"7632877\" id=\"27195852\" lat=\"45.5408932\" lon=\"-122.8675556\" timestamp=\"2011-03-21T23:25:58Z\" uid=\"393906\" user=\"Grant Humphries\" version=\"11\">\n",
      "\n",
      "\t\t<tag k=\"highway\" v=\"traffic_signals\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"8895716\" id=\"27266267\" lat=\"45.5360503\" lon=\"-122.8885243\" timestamp=\"2011-08-01T21:34:27Z\" uid=\"393906\" user=\"Grant Humphries\" version=\"7\">\n",
      "\n",
      "\t\t<tag k=\"highway\" v=\"traffic_signals\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"9726985\" id=\"27295030\" lat=\"45.5418012\" lon=\"-122.8683008\" timestamp=\"2011-11-03T00:11:51Z\" uid=\"362111\" user=\"Mele Sax-Barnett\" version=\"7\">\n",
      "\n",
      "\t\t<tag k=\"highway\" v=\"traffic_signals\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"7632877\" id=\"27526582\" lat=\"45.5174292\" lon=\"-122.8026621\" timestamp=\"2011-03-21T23:25:57Z\" uid=\"393906\" user=\"Grant Humphries\" version=\"16\" />\n",
      "\n",
      "\t<node changeset=\"9134483\" id=\"27545312\" lat=\"45.4932047\" lon=\"-122.8324784\" timestamp=\"2011-08-27T02:51:56Z\" uid=\"393906\" user=\"Grant Humphries\" version=\"7\" />\n",
      "\n",
      "\t<node changeset=\"14605675\" id=\"29096994\" lat=\"45.4275446\" lon=\"-122.7578743\" timestamp=\"2013-01-11T02:23:57Z\" uid=\"393906\" user=\"Grant Humphries\" version=\"7\" />\n",
      "\n",
      "\t<node changeset=\"9052691\" id=\"29774163\" lat=\"45.5149304\" lon=\"-122.7956232\" timestamp=\"2011-08-17T22:43:00Z\" uid=\"362111\" user=\"Mele Sax-Barnett\" version=\"6\" />\n",
      "\n",
      "\t<node changeset=\"7612506\" id=\"29774738\" lat=\"45.4642967\" lon=\"-122.7861334\" timestamp=\"2011-03-20T03:44:26Z\" uid=\"393906\" user=\"Grant Humphries\" version=\"4\" />\n",
      "\n",
      "\t<node changeset=\"8868335\" id=\"29774815\" lat=\"45.4260481\" lon=\"-122.7525111\" timestamp=\"2011-07-30T00:46:31Z\" uid=\"393906\" user=\"Grant Humphries\" version=\"7\" />\n",
      "\n",
      "\t<node changeset=\"15533044\" id=\"29774951\" lat=\"45.5049952\" lon=\"-122.7813562\" timestamp=\"2013-03-29T01:15:56Z\" uid=\"393906\" user=\"Grant Humphries\" version=\"6\" />\n",
      "\n",
      "\t<node changeset=\"11282416\" id=\"29775020\" lat=\"45.4999856\" lon=\"-122.7899169\" timestamp=\"2012-04-12T23:24:27Z\" uid=\"362111\" user=\"Mele Sax-Barnett\" version=\"5\" />\n",
      "\n",
      "\t<node changeset=\"9792735\" id=\"29775102\" lat=\"45.505258\" lon=\"-122.7813431\" timestamp=\"2011-11-10T22:02:41Z\" uid=\"362111\" user=\"Mele Sax-Barnett\" version=\"3\" />\n",
      "\n",
      "\t<node changeset=\"34109578\" id=\"29788486\" lat=\"45.5339897\" lon=\"-122.8901968\" timestamp=\"2015-09-18T19:12:04Z\" uid=\"331031\" user=\"baradam\" version=\"6\" />\n",
      "\n",
      "\t<node changeset=\"78571\" id=\"29896176\" lat=\"45.59962\" lon=\"-123.50876\" timestamp=\"2007-06-03T06:30:20Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\n",
      "\t\t<tag k=\"created_by\" v=\"JOSM\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"78571\" id=\"29896229\" lat=\"45.600697\" lon=\"-123.51126\" timestamp=\"2007-06-03T06:30:41Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\n",
      "\t\t<tag k=\"created_by\" v=\"JOSM\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"78571\" id=\"29896274\" lat=\"45.601493\" lon=\"-123.51342\" timestamp=\"2007-06-03T06:30:59Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\n",
      "\t\t<tag k=\"created_by\" v=\"JOSM\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"78571\" id=\"29896330\" lat=\"45.604089\" lon=\"-123.516341\" timestamp=\"2007-06-03T06:31:21Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\n",
      "\t\t<tag k=\"created_by\" v=\"JOSM\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"78571\" id=\"29896371\" lat=\"45.606026\" lon=\"-123.517417\" timestamp=\"2007-06-03T06:31:37Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\n",
      "\t\t<tag k=\"created_by\" v=\"JOSM\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"78571\" id=\"29896428\" lat=\"45.607386\" lon=\"-123.515345\" timestamp=\"2007-06-03T06:31:59Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\n",
      "\t\t<tag k=\"created_by\" v=\"JOSM\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"78571\" id=\"29896487\" lat=\"45.608136\" lon=\"-123.517901\" timestamp=\"2007-06-03T06:32:23Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\n",
      "\t\t<tag k=\"created_by\" v=\"JOSM\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"78571\" id=\"29896542\" lat=\"45.609265\" lon=\"-123.51903\" timestamp=\"2007-06-03T06:32:45Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\n",
      "\t\t<tag k=\"created_by\" v=\"JOSM\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"78571\" id=\"29896641\" lat=\"45.610865\" lon=\"-123.51712\" timestamp=\"2007-06-03T06:33:16Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\n",
      "\t\t<tag k=\"created_by\" v=\"JOSM\" />\n",
      "\n",
      "\t</node>\n",
      "\n",
      "\t<node changeset=\"78571\" id=\"29896996\" lat=\"45.61289\" lon=\"-123.51497\" timestamp=\"2007-06-03T06:34:01Z\" uid=\"7168\" user=\"DaveHansenTiger\" version=\"1\">\n",
      "\n",
      "\t\t<tag k=\"created_by\" v=\"JOSM\" />\n",
      "\n",
      "\t</node>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_look(SAMPLE_FILE, 50) # look at first 50 rows of sample file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node': 260076, 'relation': 248, 'way': 33432}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Since the OSM data in XML is structured under various \"tags\", we first investigate which tags exist\n",
    "as well as the quantity of each. The function below counts types of tags, storing the info in\n",
    "a dictionay named tags. The get_element function (utilized throughout my data munging code) is used to reduce the memory\n",
    "footprint using root.clear()\n",
    "\"\"\"\n",
    "\n",
    "import pprint\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    \n",
    "    for element in get_element(filename):\n",
    "        if element.tag not in tags:\n",
    "            tags[element.tag] = 1  \n",
    "                       \n",
    "        elif element.tag in tags:\n",
    "            tags[element.tag] += 1\n",
    "                    \n",
    "    return tags \n",
    "    \n",
    "def test():\n",
    "\n",
    "    tags = count_tags(SAMPLE_FILE)\n",
    "    pprint.pprint(tags)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 0, 'lower_colon': 0, 'other': 0, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\"\"\"\n",
    "The functions below explore the OSM data further. We check the\n",
    "\"k\" value for each \"<tag>\" and see if there are any potential problems using regex.\n",
    "We would like to change the data model and expand the \"addr:street\" type of keys to a dictionary like this:\n",
    "{\"address\": {\"street\": \"Some value\"}} \n",
    "So, we have to see if we have such tags, and if we have any tags with\n",
    "problematic characters, which we will compile in a dictionary as follows:\n",
    "\n",
    "  \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "  \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "  \"problemchars\", for tags with problematic characters, and\n",
    "  \"other\", for other tags that do not fall into the other three categories.\n",
    "\"\"\"\n",
    "\n",
    "# regex \n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    \n",
    "    if element.tag == \"tag\":       \n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    \n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for element in get_element(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    \n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    keys = process_map(SAMPLE_FILE)\n",
    "    pprint.pprint(keys)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 567\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\"\"\" \n",
    "The function process_map returns a set of unique user IDs (\"uid\") so we can see how many unique users there are.\n",
    "\"\"\"\n",
    "\n",
    "def get_user(element):\n",
    "    if 'uid' in element.attrib:\n",
    "        user = element.attrib['uid']\n",
    "        return user\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for element in get_element(filename):\n",
    "        if get_user(element):\n",
    "            users.add(get_user(element))\n",
    "    return users\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    users = process_map(SAMPLE_FILE)\n",
    "    print \"Number of unique users: \" + str(len(users))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'155th': set(['Southwest 155th']),\n",
      " '211': set(['Highway 211', 'Southeast Highway 211']),\n",
      " '212': set(['Southeast Highway 212']),\n",
      " '213': set(['Highway 213', 'South Highway 213']),\n",
      " '224': set(['Southeast Highway 224']),\n",
      " '47': set(['Southwest Old Highway 47']),\n",
      " '99': set(['Northeast Highway 99']),\n",
      " '99E': set(['Highway 99E']),\n",
      " '99W': set(['Northeast State Highway 99W', 'Southwest Old Highway 99W']),\n",
      " 'Ave.': set(['NW 19th Ave.', 'Northeast 122ND Ave.']),\n",
      " 'Blvd.': set(['21200 Northwest Rock Creek Blvd.']),\n",
      " 'Broadway': set(['Northeast Broadway', 'Southwest Broadway']),\n",
      " 'Byway': set(['Southwest Kings Byway']),\n",
      " 'Cervantes': set(['Cervantes']),\n",
      " 'Churchill': set(['Southwest Churchill']),\n",
      " 'Curve': set(['Horseshoe Curve']),\n",
      " 'D': set(['Northeast 82nd Avenue #D']),\n",
      " 'Downs': set(['Churchill Downs']),\n",
      " 'Dr': set(['SW Griffith Dr']),\n",
      " 'Fieldcrest': set(['Southeast Fieldcrest']),\n",
      " 'Jamaica': set(['Southwest Jamaica']),\n",
      " 'Miami': set(['Southwest Miami']),\n",
      " 'Northbound': set(['I5 Freeway Northbound']),\n",
      " 'Path': set(['Southwest Pawnee Path']),\n",
      " 'Pimlico': set(['Pimlico']),\n",
      " 'Preakness': set(['Southwest Preakness']),\n",
      " 'Rd': set(['SW Brockman Rd', 'SW Walker Rd']),\n",
      " 'South': set(['Sequoia Court South',\n",
      "               'Southeast Roanoke Court South',\n",
      "               'Southwest Canyon Creek Road South',\n",
      "               'Southwest Wimbledon Circle South']),\n",
      " 'St': set(['SW 2nd St']),\n",
      " 'Touchstone': set(['Touchstone']),\n",
      " 'View': set(['Southeast Shannon View']),\n",
      " 'West': set(['Northeast Orenco Station Parkway West',\n",
      "              'Southwest Town Center Loop West',\n",
      "              'Southwest Willamette Way West'])}\n",
      "Southeast Highway 212 => Southeast Highway 212\n",
      "Highway 213 => Highway 213\n",
      "South Highway 213 => South Highway 213\n",
      "Pimlico => Pimlico\n",
      "Highway 211 => Highway 211\n",
      "Southeast Highway 211 => Southeast Highway 211\n",
      "Southwest Town Center Loop West => Southwest Town Center Loop West\n",
      "Northeast Orenco Station Parkway West => Northeast Orenco Station Parkway West\n",
      "Southwest Willamette Way West => Southwest Willamette Way West\n",
      "SW Walker Rd => SW Walker Road\n",
      "SW Brockman Rd => SW Brockman Road\n",
      "I5 Freeway Northbound => I5 Freeway Northbound\n",
      "Southeast Fieldcrest => Southeast Fieldcrest\n",
      "Southwest Old Highway 99W => Southwest Old Highway 99W\n",
      "Northeast State Highway 99W => Northeast State Highway 99W\n",
      "Southwest Preakness => Southwest Preakness\n",
      "Southwest Old Highway 47 => Southwest Old Highway 47\n",
      "Churchill Downs => Churchill Downs\n",
      "Highway 99E => Highway 99E\n",
      "Southwest Wimbledon Circle South => Southwest Wimbledon Circle South\n",
      "Sequoia Court South => Sequoia Court South\n",
      "Southeast Roanoke Court South => Southeast Roanoke Court South\n",
      "Southwest Canyon Creek Road South => Southwest Canyon Creek Road South\n",
      "Southwest Pawnee Path => Southwest Pawnee Path\n",
      "Southeast Shannon View => Southeast Shannon View\n",
      "SW Griffith Dr => SW Griffith Drive\n",
      "Southwest Kings Byway => Southwest Kings Byway\n",
      "NW 19th Ave. => NW 19th Avenue\n",
      "Northeast 122ND Ave. => Northeast 122ND Avenue\n",
      "Northeast 82nd Avenue #D => Northeast 82nd Avenue #D\n",
      "Southwest Miami => Southwest Miami\n",
      "Horseshoe Curve => Horseshoe Curve\n",
      "Southwest 155th => Southwest 155th\n",
      "SW 2nd St => SW 2nd Street\n",
      "Northeast Highway 99 => Northeast Highway 99\n",
      "Cervantes => Cervantes\n",
      "Southeast Highway 224 => Southeast Highway 224\n",
      "Touchstone => Touchstone\n",
      "21200 Northwest Rock Creek Blvd. => 21200 Northwest Rock Creek Boulevard\n",
      "Southwest Jamaica => Southwest Jamaica\n",
      "Southwest Churchill => Southwest Churchill\n",
      "Southwest Broadway => Southwest Broadway\n",
      "Northeast Broadway => Northeast Broadway\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "osmfile = \"sample.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# 10/31 added Terrace, Circle \n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Terrace\", \"Circle\", \"Circus\", \"Crescent\", \"Crest\", \"East\", \"End\",\n",
    "            \"Highway\", \"Loop\", \"North\", \"Run\", \"Terrace\", \"Way\"]\n",
    "\n",
    "# Added Ave. and Blvd\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\": \"Road\", \n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Hwy\": \"Highway\"\n",
    "            }\n",
    "\n",
    "# this function uses regex to add \"unexpected\" street types to the street_types set\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group() # grabs output of regex (last part of string) and assigns to street_type\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "# this function returns True if the k element is \"addr:street\"\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "# this is the main audit function \n",
    "# takes osmfile and opens it\n",
    "# creates street_types dictionary of sets\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    # for all node and way tags, iterate through the child tags and if the tag is \"tag\"\n",
    "    # check if it's a stree name: if yes, then call audit_street_type function\n",
    "    #for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "    for i, elem in enumerate(get_element(osmfile)):    # inserted this to preserve memory\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "    \n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    address_list = name.split()\n",
    "    #print address_list[-1]\n",
    "    if address_list[-1] in mapping:\n",
    "        address_list[-1] = mapping[address_list[-1]]\n",
    "        name = \" \".join(str(x) for x in address_list)\n",
    "    return name   \n",
    "\n",
    "\n",
    "def test():\n",
    "    st_types = audit(osmfile)\n",
    "    #assert len(st_types) == 3\n",
    "    pprint.pprint(dict(st_types))\n",
    "\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)    \n",
    "            print name, \"=>\", better_name\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken To Audit Attributes: 3.7650001049 seconds\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "# I used functions below to look at all the possible attributes and then select various ones to investigate for issues\n",
    "\n",
    "ATT_FILE = \"sample_attributes\"\n",
    "\n",
    "attrib_set = set() # set of all unique attributes in dataset\n",
    "attrib_list = set() # for a given attribute, set of all unique values\n",
    "\n",
    "\n",
    "# Call this function to collect the 'k' attributes as a set\n",
    "def child_k_info(attrib_set, element):\n",
    "    for child in element:\n",
    "        if child.tag == 'tag':\n",
    "            attrib_set.add(child.attrib['k'])\n",
    "    return attrib_set         \n",
    "\n",
    "# Call this function to investigate a particular 'k' attribute \n",
    "def att_info(attrib_dict, element, k_attribute):\n",
    "    for child in element:\n",
    "        if child.tag == 'tag':\n",
    "            if child.attrib['k'] == k_attribute:\n",
    "                attrib_list.add(child.attrib['v'])\n",
    "    return attrib_list     \n",
    "\n",
    "k_attribute = 'landuse'\n",
    "    \n",
    "# Call the auditing functions\n",
    "t0 = time()\n",
    "for i, element in enumerate(get_element(SAMPLE_FILE)):\n",
    "    attrib_set = child_k_info(attrib_set, element)\n",
    "    attrib_list = att_info(attrib_set, element, k_attribute)\n",
    "    element.clear()\n",
    "print 'Time Taken To Audit Attributes: {} seconds'.format(time()-t0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prints all the attributes\n",
    "#pprint(attrib_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['basin',\n",
      "     'brownfield',\n",
      "     'cemetery',\n",
      "     'commercial',\n",
      "     'construction',\n",
      "     'farm',\n",
      "     'farmland',\n",
      "     'farmyard',\n",
      "     'forest',\n",
      "     'garages',\n",
      "     'government',\n",
      "     'grass',\n",
      "     'greenhouse_horticulture',\n",
      "     'industrial',\n",
      "     'landfill',\n",
      "     'meadow',\n",
      "     'military',\n",
      "     'orchard',\n",
      "     'plant_nursery',\n",
      "     'quarry',\n",
      "     'railway',\n",
      "     'reservoir',\n",
      "     'residential',\n",
      "     'retail',\n",
      "     'village_green',\n",
      "     'vineyard'])\n"
     ]
    }
   ],
   "source": [
    "# prin attrib_list generated for particular 'k' attribute in att_info function above\n",
    "pprint(attrib_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to do specific audit of each of the k attributes and then correct them in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create mappings for k attribute 'landuse'\n",
    "\n",
    "landuse_mapping = [\"farmland\", \"farmyard\"]\n",
    "\n",
    "def is_landuse(elem):\n",
    "    return (elem.attrib['k'] == \"landuse\")\n",
    "\n",
    "def update_landuse(name, landuse_mapping):\n",
    "    if name in landuse_mapping:\n",
    "        name = \"farm\"\n",
    "    return name   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create mappings for k attribute 'name' Starbucks\n",
    "\n",
    "starbucks_mapping = [\"Starbucks\"]\n",
    "\n",
    "def is_name(elem):\n",
    "    return (elem.attrib['k'] == \"name\")\n",
    "\n",
    "def update_name_starbucks(name, starbucks_mapping):\n",
    "    if name in starbucks_mapping:\n",
    "        name = \"Starbucks Coffee\"\n",
    "    return name   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "OSM_PATH = \"sample.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, node_tags = NODE_TAGS_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, way_n_fields = WAY_NODES_FIELDS, default_tag_type='regular'):\n",
    "    \n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for tag in node_attr_fields:\n",
    "            node_attribs[tag] = element.get(tag)\n",
    "\n",
    "        for child in element.iter(\"tag\"):\n",
    "            # update street names if neccesary\n",
    "            if is_street_name(child):\n",
    "                child.attrib['v'] = update_name(child.attrib['v'], mapping)\n",
    "                \n",
    "            # update landuse if necessary\n",
    "            elif is_landuse(child):\n",
    "                child.attrib['v'] = update_landuse(child.attrib['v'], landuse_mapping)\n",
    "            \n",
    "            # update name if Starbucks to Starbucks Coffee\n",
    "            elif is_name(child):\n",
    "                child.attrib['v'] = update_name_starbucks(child.attrib['v'], starbucks_mapping)\n",
    "            \n",
    "            \n",
    "            sec_tag = {el:0 for el in node_tags}\n",
    "            sec_tag['id'] = node_attribs['id']\n",
    "            \n",
    "            sec_tag['value'] = child.attrib['v']\n",
    "            \n",
    "            if PROBLEMCHARS.search(child.attrib[\"k\"]):\n",
    "                continue\n",
    "                \n",
    "            elif \":\" in child.attrib['k']:\n",
    "                sec_tag['type'] = child.attrib['k'][:child.attrib['k'].find(\":\")]\n",
    "                sec_tag['key'] = child.attrib['k'][child.attrib['k'].find(\":\")+1:]\n",
    "                \n",
    "            else:\n",
    "                sec_tag['type'] = 'regular'\n",
    "                sec_tag['key'] = child.attrib['k']\n",
    "                \n",
    "            tags.append(sec_tag)    \n",
    "        \n",
    "        tag_return = {'node': node_attribs, 'node_tags': tags}\n",
    "        #print tag_return\n",
    "        return {'node': node_attribs, 'node_tags': tags}  \n",
    "    \n",
    "        #print node_attribs\n",
    "        #print tags\n",
    "        #print \"\"\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        way_attribs = {el:0 for el in way_attr_fields}\n",
    "        for tag in way_attr_fields:\n",
    "            way_attribs[tag] = element.attrib[tag]\n",
    "        \n",
    "        # handle way tags\n",
    "        for child in element.iter(\"tag\"):\n",
    "            \n",
    "            # update street names if neccesary\n",
    "            if is_street_name(child):\n",
    "                child.attrib['v'] = update_name(child.attrib['v'], mapping)   \n",
    "                \n",
    "            # update landuse if necessary\n",
    "            elif is_landuse(child):\n",
    "                child.attrib['v'] = update_landuse(child.attrib['v'], landuse_mapping)\n",
    "             \n",
    "            # update name if Starbucks to Starbucks Coffee\n",
    "            elif is_name(child):\n",
    "                child.attrib['v'] = update_name_starbucks(child.attrib['v'], starbucks_mapping)\n",
    "            \n",
    "            sec_tag = {el:0 for el in node_tags}\n",
    "            sec_tag['id'] = way_attribs['id']\n",
    "            \n",
    "            sec_tag['value'] = child.attrib['v']\n",
    "            \n",
    "            if PROBLEMCHARS.search(child.attrib[\"k\"]):\n",
    "                continue\n",
    "                \n",
    "            elif \":\" in child.attrib['k']:\n",
    "                sec_tag['type'] = child.attrib['k'][:child.attrib['k'].find(\":\")]\n",
    "                sec_tag['key'] = child.attrib['k'][child.attrib['k'].find(\":\")+1:]\n",
    "                \n",
    "            else:\n",
    "                sec_tag['type'] = 'regular'\n",
    "                sec_tag['key'] = child.attrib['k']\n",
    "                \n",
    "            tags.append(sec_tag)  \n",
    "    \n",
    "\n",
    "        # handle way nodes\n",
    "        position = 0\n",
    "        for child in element.iter(\"nd\"):\n",
    "            #way_node = {el:0 for el in way_n_fields}\n",
    "            way_node = {}\n",
    "            way_node['id'] = way_attribs['id']\n",
    "            way_node['node_id'] = child.attrib['ref']\n",
    "            way_node['position'] = position\n",
    "            way_nodes.append(way_node)\n",
    "            position += 1\n",
    "            \n",
    "        \n",
    "        way_return = {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "        #print way_return\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
